{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1325c5f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%pip install python-dotenv openai azure-identity instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd641ad-1c89-4f5a-aa7d-4d6930207060",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Agenda\n",
    "\n",
    "1. Chat Completions\n",
    "   * Message Types\n",
    "   * Request Parameters\n",
    "   * Prompt Engineering\n",
    "   * Structured Output\n",
    "   * Tool Calling\n",
    "2. Retrieval Augmented Generation\n",
    "   * Vector Databases\n",
    "   * Visualizing Semantic Similarity\n",
    "   * Hybrid Search and Reranking\n",
    "3. Promptflow\n",
    "   * Anatomy of a flow\n",
    "   * Evaluations + Benchmarking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958072a-29b9-4f85-999b-b79664453277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b992fc3-89df-4cff-88bd-6d921330e8bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Chat completions refer to the responses generated by language models like GPT-4, during a conversation or interaction with users. These responses are crafted based on the input received, context, and predefined instructions or system messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729bf4f-5e16-4503-8197-f12497f34fec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These models produce probabilistic output by assigning weights to different parts of the input during inference, determining the likelihood of each possible next word or phrase based on its surrounding contextual relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0c9ed-651b-4565-a133-02bd5bba8dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Message Types\n",
    "\n",
    "* User Messages\n",
    "* System Messages\n",
    "* Assistant Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e64f39-e228-4bdd-9d6a-bea9802e5ac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### User Messages\n",
    "\n",
    "* Messages sent by the user to the AI.\n",
    "* Usually in the form of questions, commands, or conversational input.\n",
    "* Example: \"How do I make an omelette?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ad158",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### System Messages\n",
    "\n",
    "* Instructions provided to guide the AI’s behavior\n",
    "* The model weighs instructions here much more than other message types\n",
    "* Example: \"You are a british chef and restauranteur with a short and fiery temper”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf0b45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Assistant Messages\n",
    "\n",
    "* Responses generated by the AI\n",
    "* Typically reserved for replies to user inputs based on the context and instructions.\n",
    "* Example: \"Make the bloody omelette you donkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86cf3b78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butter the pan, crack the eggs in a bowl, whisk 'em like you mean it. Throw it in, don't fiddle about, and slide that flipping thing out before it burns!  Now get outta my kitchen. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = ollama_client.chat.completions.create(\n",
    "    model = \"gemma2:9b\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"name\": \"gordon_ramsay\",\n",
    "            \"content\": \"You are a british chef and restauranteur with a short and fiery temper. Keep your responses rude and curt.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"name\": \"amateur_chef\",\n",
    "            \"content\": \"How do I make an omelette?\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if (len(chunk.choices) > 0 and chunk.choices[0].delta.content):\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150340c3-d5d4-4a9c-9802-49eb47f61673",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Request Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f1d1c-6c67-49f9-bdfe-9c51c45b54d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Top Logprobs (logprobs, top_logprobs)\n",
    "* Limiting Parameters (max_tokens, n, stop sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d621183-11e9-4dbe-82ff-ab3bcb4fa862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Top Logprobs\n",
    "\n",
    "* logprobs: Boolean that if true, will return log probabilities of output tokens.\n",
    "* top_logprobs: Number of most likely tokens to return at each token position.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3bdb7-b03a-4d2f-aa9c-e9416cf27aaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Top Logprobs\n",
    "\n",
    "* logprobs: Boolean that if true, will return log probabilities of output tokens.\n",
    "* top_logprobs: Number of most likely tokens to return at each token position.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4045d-e67c-4d51-9099-4982fd2327b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Use Cases:**\n",
    "\n",
    "* Classification: Set confidence thresholds based on probabilities\n",
    "* Retrieval Evaluation: Self-evaluation with confidence scores\n",
    "* Autocomplete: Assist in word suggestion as a user types\n",
    "* Calculating Perplexity: Compare confidence of results across different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee6e557f-669a-4b99-9f45-c1bd311c99a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': 'true', 'logprobs': -0.00014716439, 'probability': 99.99}\n",
      "{'token': 'True', 'logprobs': -9.126677, 'probability': 0.01}\n",
      "{'token': 'false', 'logprobs': -10.310749, 'probability': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")\n",
    "\n",
    "instruction = \"\"\"\n",
    "You will be given text describing some food.  Your task is to determine if that food is spicy.\n",
    "\n",
    "Examples:\n",
    "pepper = true\n",
    "milk = false\n",
    "\n",
    "Expected Output: \n",
    "true or false NOTHING ELSE\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": \"jolokia = \"}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3\n",
    ")\n",
    "\n",
    "top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "for logprob in top_logprobs:\n",
    "    print({\n",
    "        \"token\": logprob.token,\n",
    "        \"logprobs\": logprob.logprob,\n",
    "        \"probability\": np.round(np.exp(logprob.logprob) * 100, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7740dad-5d58-448d-8195-641d5c2025b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac080799-a123-472b-b2ca-144622a89c65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfff9dc-3f02-4fb0-a67a-99f71b5fa0d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8385ba2a-ea8f-4e53-a15c-cb2f31ebd595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Harry Potter\",\n",
      "  \"age\": 17,\n",
      "  \"fact\": [\n",
      "    \"He is a wizard.\",\n",
      "    \"His parents were murdered by Lord Voldemort.\",\n",
      "    \"He has a scar shaped like a lightning bolt on his forehead.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import instructor\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    fact: List[str] = Field(..., description=\"A list of facts about the character\")\n",
    "\n",
    "\n",
    "# enables `response_model` in create call\n",
    "client = instructor.from_openai(\n",
    "    OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\"), \n",
    "    mode=instructor.Mode.JSON,\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gemma2:9b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about the Harry Potter\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=Character,\n",
    ")\n",
    "print(resp.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569925e3-3e5b-45a4-a7b3-a3326ef96680",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Tool Calling\n",
    "* Normal Tools with OpenAPI specs\n",
    "* Semantic Kernel Auto Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1251f68-17f0-4e70-a443-8e2ed3715664",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542871d-7616-4b80-bc66-5f0441868a1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75d336-0fe1-44ba-a176-763b632341c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbccff-ad10-4c5e-889d-6996876a199c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac467b-aafb-4067-b4d9-2812c27707a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Visualizing Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498093e-d3b7-47ec-af17-730809b31c42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b1c91-85ea-4a1d-86bf-e4fdefec46bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Hybrid Search and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd08a7c-abe9-4731-b4a7-b584d5165044",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e687cd3-f64a-401f-bbcf-e43b2afe8edb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Promptflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1792a-0c8c-40c4-83cd-43de6ce54f3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Anatomy of a flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad28ac9-91ba-4bb9-855d-29cfbf168a9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c3644-21f5-4929-b4d3-4e0ae6d7fd8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Evaluations + Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3c44a-7d75-4e70-bf92-760f75e759c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
