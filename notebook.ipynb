{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1325c5f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%pip install python-dotenv openai azure-identity instructor semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd641ad-1c89-4f5a-aa7d-4d6930207060",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Agenda\n",
    "\n",
    "1. Chat Completions\n",
    "   * Message Types\n",
    "   * Request Parameters\n",
    "   * Prompt Engineering\n",
    "   * Structured Output\n",
    "   * Function Calling\n",
    "2. Retrieval Augmented Generation\n",
    "   * Vector Databases\n",
    "   * Visualizing Semantic Similarity\n",
    "   * Hybrid Search and Reranking\n",
    "3. Promptflow\n",
    "   * Anatomy of a flow\n",
    "   * Evaluations + Benchmarking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958072a-29b9-4f85-999b-b79664453277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b992fc3-89df-4cff-88bd-6d921330e8bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Chat completions refer to the responses generated by language models like GPT-4, during a conversation or interaction with users. These responses are crafted based on the input received, context, and predefined instructions or system messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729bf4f-5e16-4503-8197-f12497f34fec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These models produce probabilistic output by assigning weights to different parts of the input during inference, determining the likelihood of each possible next word or phrase based on its surrounding contextual relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0c9ed-651b-4565-a133-02bd5bba8dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Message Types\n",
    "\n",
    "* User Messages\n",
    "* System Messages\n",
    "* Assistant Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e64f39-e228-4bdd-9d6a-bea9802e5ac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### User Messages\n",
    "\n",
    "* Messages sent by the user to the AI.\n",
    "* Usually in the form of questions, commands, or conversational input.\n",
    "* Example: \"How do I make an omelette?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ad158",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### System Messages\n",
    "\n",
    "* Instructions provided to guide the AI’s behavior\n",
    "* The model weighs instructions here much more than other message types\n",
    "* Example: \"You are a british chef and restauranteur with a short and fiery temper”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf0b45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Assistant Messages\n",
    "\n",
    "* Responses generated by the AI\n",
    "* Typically reserved for replies to user inputs based on the context and instructions.\n",
    "* Example: \"Make the bloody omelette you donkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86cf3b78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right, listen up, you muppet. Crack two eggs into a bowl, whisk 'em like you mean it. Splash in a bit of milk, salt and pepper. Fry a knob of butter in a pan, chuck the eggs in, then scramble them about till they're set. Fold it over, plate it up, and for God's sake, don't burn it. Now get outta my kitchen!  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = ollama_client.chat.completions.create(\n",
    "    model = \"gemma2:9b\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"name\": \"instruction\",\n",
    "            \"content\": \"You are a british chef and restauranteur with a short and fiery temper. Keep your responses rude and curt.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"name\": \"beginner_chef\",\n",
    "            \"content\": \"How do I make an omelette?\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if (len(chunk.choices) > 0 and chunk.choices[0].delta.content):\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150340c3-d5d4-4a9c-9802-49eb47f61673",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Request Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f1d1c-6c67-49f9-bdfe-9c51c45b54d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Token Probabilities\n",
    "* Limiting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d621183-11e9-4dbe-82ff-ab3bcb4fa862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Token Probabilities\n",
    "\n",
    "* `logprobs`: Boolean that if true, will return log probabilities of output tokens.\n",
    "* `top_logprobs`: Number of most likely tokens to return at each token position.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4045d-e67c-4d51-9099-4982fd2327b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Use Cases:**\n",
    "\n",
    "* Classification: Set confidence thresholds based on probabilities\n",
    "* Retrieval Evaluation: Self-evaluation with confidence scores\n",
    "* Autocomplete: Assist in word suggestion as a user types\n",
    "* Calculating Perplexity: Compare confidence of results across different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee6e557f-669a-4b99-9f45-c1bd311c99a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "dc1310eb-e1cf-49f3-8ff6-eb9d8ab2ec07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: salty\n",
      "token 1:\n",
      "\ttop_logprobs: s, probability: 99.92\n",
      "\ttop_logprobs: S, probability: 0.08\n",
      "\ttop_logprobs: sweet, probability: 0.0\n",
      "token 2:\n",
      "\ttop_logprobs: alty, probability: 100.0\n",
      "\ttop_logprobs: we, probability: 0.0\n",
      "\ttop_logprobs: our, probability: 0.0\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "Your task is to determine if that food is ONE of these classifications: sweet, salty, sour, bitter or umami.\n",
    "\n",
    "### Examples\n",
    "strawberry = sweet\n",
    "bacon = salty\n",
    "lemon = sour\n",
    "beer = bitter\n",
    "mushroom = umami\n",
    "\n",
    "### Expected Output\n",
    "One of sweet, salty, sour, bitter or umami. NOTHING ELSE.\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": \"baby back ribs = \"}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3\n",
    ")\n",
    "\n",
    "print(\"Prediction:\", response.choices[0].message.content)\n",
    "for i, content in enumerate(response.choices[0].logprobs.content):\n",
    "    print(f\"token {i + 1}:\")\n",
    "    for j, logprob in enumerate(content.top_logprobs):\n",
    "        probability = np.round(np.exp(logprob.logprob) * 100, 2)\n",
    "        print(f\"\\ttop_logprobs: {logprob.token}, probability: {probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5c672-0743-4103-a0ab-7dd2844c6f88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limiting Parameters\n",
    "\n",
    "* `max_tokens`: Max number of tokens to generate\n",
    "* `n`: Number of chat completion choices to generate\n",
    "* `stop`: Sequence where the API will stop generating further tokens \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b0250-231f-4526-93f6-6a981a8cfe63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Use Cases**\n",
    "* Fixed response length / cost management\n",
    "* Generating multiple options for gauging response cohesiveness\n",
    "* Strategic sequences for controlling response length\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b594a192-a002-4a17-8775-65f038df1277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e8c65b4e-9e40-43e2-94f5-318f7f96f256",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steaming bowl of broth\n",
      "Noodles, herbs, and meat abound\n",
      "Pho warms body, soul\n",
      "\n",
      "Steaming bowl of pho\n",
      "Broth so rich, noodles so fine\n",
      "Comfort in a bowl\n",
      "\n",
      "Steaming broth and noodles\n",
      "Herbs and meat in harmony\n",
      "Pho warms the soul deep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a haiku about the provided food\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pho\"}\n",
    "    ],\n",
    "    # max_tokens=100,\n",
    "    n=3\n",
    "    # stop=\"\\n\"\n",
    ")\n",
    "\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7740dad-5d58-448d-8195-641d5c2025b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac080799-a123-472b-b2ca-144622a89c65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfff9dc-3f02-4fb0-a67a-99f71b5fa0d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Structured Output\n",
    "\n",
    "* JSON Output\n",
    "* Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3858aa-cecc-47b5-a2cf-3209dcfa9b42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### JSON Output\n",
    "\n",
    "* Model is constrained to only generate strings that parse into valid JSON object\n",
    "* Must instruct the model to produce JSON somewhere in the system message\n",
    "* Formatting/examples are important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8385ba2a-ea8f-4e53-a15c-cb2f31ebd595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Pancakes', 'style': 'American'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Scrambled Eggs with Toast', 'style': 'Classic'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Oatmeal with Berries', 'style': 'Healthy'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Breakfast Burrito', 'style': 'Mexican'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Yogurt Parfait', 'style': 'Light'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "resp = ollama_client.chat.completions.create(\n",
    "    model=\"gemma2:9b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            # Task\n",
    "            You will be given a meal (breakfast/lunch/dinner). Generate a JSON list of 5 dishes for that meal.\n",
    "            \n",
    "            # Expected Format:\n",
    "            { \"dishes\": [ {\"name\": \"<dish>\", \"style\": \"<dish style>\"}, ... ] }\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"breakfast\",\n",
    "        }\n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" }\n",
    ")\n",
    "\n",
    "for dish in json.loads(resp.choices[0].message.content)[\"dishes\"]:\n",
    "    print(dish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12573ff9-6b6c-4503-b757-b7b17478fe22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6e5ae-139f-4d3b-968b-5094905dcf14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Types are important for bringing some semblance of order to an otherwise chaotic system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc6e37-86aa-47f2-89b8-f1f912a70d80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "[Pydantic](https://docs.pydantic.dev/latest/) is the defacto type validation library for Python powered by type annotations\n",
    "```python\n",
    "class DishList(BaseModel):\n",
    "    dishes: List[Dish] = Field(..., description=\"Contains a list of dish objects containing name and style\")\n",
    "\n",
    "class Dish(BaseModel):\n",
    "    name: str\n",
    "    style: str = Field(..., description=\"The dish type i.e. Mexican, Japanese etc.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e8883-ec7d-49d1-b8a8-ee186f36b501",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "[Instructor](https://python.useinstructor.com/why/) is a library that shims various LLM provider with the ability to validate and return Pydantic types\n",
    "```python\n",
    "client.chat.completions.create(\n",
    "    ...,\n",
    "    response_model=DishList\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c847ad2e-fd23-4c6b-aaa4-6961e28fc816",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dish: Pancakes, Style: American\n",
      "Dish: Scrambled Eggs, Style: Western\n",
      "Dish: Breakfast Burrito, Style: Mexican\n",
      "Dish: Avocado Toast, Style: Modern\n",
      "Dish: Oatmeal with Berries, Style: Healthy\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import instructor\n",
    "\n",
    "class DishList(BaseModel):\n",
    "    dishes: List[Dish] = Field(..., description=\"Contains a list of dish objects containing name and style\")\n",
    "\n",
    "class Dish(BaseModel):\n",
    "    name: str\n",
    "    style: str = Field(..., description=\"The dish type i.e. Mexican, Japanese etc.\")\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "instructor_client = instructor.from_openai(ollama_client, mode=instructor.Mode.JSON)\n",
    "\n",
    "response = instructor_client.chat.completions.create(\n",
    "    model=\"gemma2:9b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            # Task\n",
    "            You will be given a meal (breakfast/lunch/dinner). Generate a JSON list of 5 dishes for that meal.\n",
    "            \n",
    "            # Expected Format:\n",
    "            { \"dishes\": [ {\"name\": \"<dish>\", \"style\": \"<dish style>\"}, ... ] }\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"breakfast\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=DishList\n",
    ")\n",
    "\n",
    "for dish in response.dishes:\n",
    "    print(f\"Dish: {dish.name}, Style: {dish.style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569925e3-3e5b-45a4-a7b3-a3326ef96680",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Function Calling\n",
    "* Open AI Tools\n",
    "* Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dd985-74a1-462c-b160-b3a42bc6567f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Open AI Tools\n",
    "\n",
    "Model is constrained to predict which function(s) and argument(s) should be called to achieve a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f0d6b-17b8-416e-9daf-5fd6651af949",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Assuming we have functions like this in our codebase:\n",
    "```python\n",
    "def get_weather(location: str, unit: str):\n",
    "    return ...\n",
    "\n",
    "def google_search(query: str):\n",
    "    return ...\n",
    "```\n",
    "\n",
    "How can we get an LLM to intelligently choose which tools to call?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b97d1c-d7bc-4392-8036-04f731ff8a27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744a4d1-cf54-4c1b-bc9d-3a43c726bf12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "google_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"Queries google for a search query\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search query\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4873250d-72ab-4c92-ab28-9988ebd1de69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"location\": \"Toronto\", \"unit\": \"celsius\"}', name='get_weather')\n",
      "Function(arguments='{\"location\": \"Dallas\", \"unit\": \"celsius\"}', name='get_weather')\n",
      "Function(arguments='{\"query\": \"super bowl winner\"}', name='google_search')\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "aoai_client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")\n",
    "\n",
    "response = aoai_client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You must always use tools\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in toronto and dallas and who won the super bowl?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=[weather_tool, google_tool]\n",
    ")\n",
    "\n",
    "for tool in response.choices[0].message.tool_calls:\n",
    "    print(tool.function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fc029-e8f1-4c59-b617-73de5795e4f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Example with Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a1251f68-17f0-4e70-a443-8e2ed3715664",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Weather'> location='Toronto, ON' units='celsius'\n",
      "<class '__main__.Weather'> location='Dallas, TX' units='celsius'\n",
      "<class '__main__.GoogleSearch'> query='super bowl winner'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Iterable, Literal\n",
    "import instructor\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    location: str = Field(..., description = \"The city and state, e.g. San Francisco, CA\")\n",
    "    units: Literal[\"celsius\", \"fahrenheit\"]\n",
    "\n",
    "class GoogleSearch(BaseModel):\n",
    "    query: str = Field(..., description = \"The search query\")\n",
    "\n",
    "instructor_client = instructor.from_openai(aoai_client, mode=instructor.Mode.PARALLEL_TOOLS)\n",
    "\n",
    "response = instructor_client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You must always use tools\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in toronto and dallas and who won the super bowl?\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=Iterable[Weather | GoogleSearch]\n",
    ")\n",
    "\n",
    "for function in response:\n",
    "    print(type(function), function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0d34f-6e2b-44f9-aff6-2d5672674807",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Semantic Kernel\n",
    "\n",
    "An [open-source library](https://learn.microsoft.com/en-us/semantic-kernel/overview/) that lets you build AI agents and integrate the latest AI models with bindings in C#, Python, and Java."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf2beb-41d2-4d7e-b894-ebf33d364f99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "For this talk, we'll focus on SK within the lens of function calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7dc26-a130-4c4d-9a1c-89d63aa9b7e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Initializing Kernel**\n",
    "\n",
    "Configures the LLM available to an instance of Semantic Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "299d4737-4f67-4940-9ad3-639dc7b95271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "        endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\",\n",
    "        deployment_name=\"gpt-35-turbo\",\n",
    "        ad_token_provider=token_provider\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203da0b-f125-46b4-b426-f7388d54ed19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Initializing Native Plugins**\n",
    "\n",
    "Defines types and functions the LLM has access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b8e467f5-fe9b-4747-9d0b-7e981c6ca702",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, TypedDict, Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "import random\n",
    "\n",
    "class Weather(TypedDict):\n",
    "    location: str\n",
    "    unit: str\n",
    "    temperature: float\n",
    "\n",
    "class WeatherPlugin:\n",
    "   @kernel_function(\n",
    "      name=\"get_weather\",\n",
    "      description=\"Get the current weather in a given location\",\n",
    "   )\n",
    "   def get_weather(self, \n",
    "                   location: Annotated[str, \"Location to retrieve weather for\"], \n",
    "                   unit: Annotated[str, \"celsius or fahrenheit\"]) -> Annotated[Weather, \"The weather for a given location\"]:\n",
    "      return Weather(location=location, unit=unit, temperature=random.randint(10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38d9c3-9341-4e98-b78f-f3d023dd332a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Executing the Kernel**\n",
    "\n",
    "Same canonical example as the previous section, but SK automatically invokes our native Python functions for us automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "51bd1848-2f49-4f10-be87-e3ff76fcdcc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > Currently, the weather in Toronto is 96°F and the weather in San Antonio is 25°F.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"Weather\",)\n",
    "\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Enable auto-function calling\n",
    "execution_settings = AzureChatPromptExecutionSettings(tool_choice=\"auto\")\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_message({\"role\": \"user\", \"content\": \"What's the weather in Toronto and San Antonio in freedom units?\"})\n",
    "\n",
    "# Get the response from the AI\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "  chat_history=history,\n",
    "  settings=execution_settings,\n",
    "  kernel=kernel,\n",
    "  arguments=KernelArguments(),\n",
    "))[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Assistant > \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542871d-7616-4b80-bc66-5f0441868a1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75d336-0fe1-44ba-a176-763b632341c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbccff-ad10-4c5e-889d-6996876a199c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac467b-aafb-4067-b4d9-2812c27707a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Visualizing Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498093e-d3b7-47ec-af17-730809b31c42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b1c91-85ea-4a1d-86bf-e4fdefec46bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Hybrid Search and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd08a7c-abe9-4731-b4a7-b584d5165044",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e687cd3-f64a-401f-bbcf-e43b2afe8edb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Promptflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1792a-0c8c-40c4-83cd-43de6ce54f3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Anatomy of a flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad28ac9-91ba-4bb9-855d-29cfbf168a9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c3644-21f5-4929-b4d3-4e0ae6d7fd8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Evaluations + Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3c44a-7d75-4e70-bf92-760f75e759c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
