{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1325c5f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%pip install python-dotenv openai azure-identity instructor semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd641ad-1c89-4f5a-aa7d-4d6930207060",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Agenda\n",
    "\n",
    "1. Chat Completions\n",
    "   * Message Types\n",
    "   * Request Parameters\n",
    "   * Structured Output\n",
    "   * Function Calling\n",
    "   * Agents with Semantic Kernel\n",
    "2. Retrieval Augmented Generation\n",
    "   * Vector Databases\n",
    "   * Visualizing Semantic Similarity\n",
    "   * Hybrid Search and Reranking\n",
    "3. Promptflow\n",
    "   * Anatomy of a flow\n",
    "   * Evaluations + Benchmarking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958072a-29b9-4f85-999b-b79664453277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b992fc3-89df-4cff-88bd-6d921330e8bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Chat completions refer to the responses generated by language models like GPT-4, during a conversation or interaction with users. These responses are crafted based on the input received, context, and predefined instructions or system messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729bf4f-5e16-4503-8197-f12497f34fec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These models produce probabilistic output by assigning weights to different parts of the input during inference, determining the likelihood of each possible next word or phrase based on its surrounding contextual relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0c9ed-651b-4565-a133-02bd5bba8dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Message Types\n",
    "\n",
    "* User Messages\n",
    "* System Messages\n",
    "* Assistant Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e64f39-e228-4bdd-9d6a-bea9802e5ac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### User Messages\n",
    "\n",
    "* Messages sent by the user to the AI.\n",
    "* Usually in the form of questions, commands, or conversational input.\n",
    "* Example: \"How do I make an omelette?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ad158",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### System Messages\n",
    "\n",
    "* Instructions provided to guide the AI’s behavior\n",
    "* The model weighs instructions here much more than other message types\n",
    "* Example: \"You are a british chef and restauranteur with a short and fiery temper”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf0b45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Assistant Messages\n",
    "\n",
    "* Responses generated by the AI\n",
    "* Typically reserved for replies to user inputs based on the context and instructions.\n",
    "* Example: \"Make the bloody omelette you donkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cf3b78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right, listen up. You crack two eggs, whisk 'em good. Chuck in a knob of butter in the pan - hot, not bloody scorching -  pour in the eggs. Now scramble it about like you're possessed till it's almost set, then fold it over and get it outta there. \n",
      "\n",
      "You want fancy? Add cheese or somethin'.  Don't muck it up.  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = ollama_client.chat.completions.create(\n",
    "    model = \"gemma2:9b\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"name\": \"instruction\",\n",
    "            \"content\": \"You are a british chef and restauranteur with a short and fiery temper. Keep your responses rude and curt.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"name\": \"beginner_chef\",\n",
    "            \"content\": \"How do I make an omelette?\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if (len(chunk.choices) > 0 and chunk.choices[0].delta.content):\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150340c3-d5d4-4a9c-9802-49eb47f61673",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Request Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f1d1c-6c67-49f9-bdfe-9c51c45b54d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Token Probabilities\n",
    "* Limiting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d621183-11e9-4dbe-82ff-ab3bcb4fa862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Token Probabilities\n",
    "\n",
    "* `logprobs`: Boolean that if true, will return log probabilities of output tokens.\n",
    "* `top_logprobs`: Number of most likely tokens to return at each token position.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4045d-e67c-4d51-9099-4982fd2327b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Use Cases:**\n",
    "\n",
    "* Classification: Set confidence thresholds based on probabilities\n",
    "* Retrieval Evaluation: Self-evaluation with confidence scores\n",
    "* Autocomplete: Assist in word suggestion as a user types\n",
    "* Calculating Perplexity: Compare confidence of results across different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6e557f-669a-4b99-9f45-c1bd311c99a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1310eb-e1cf-49f3-8ff6-eb9d8ab2ec07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: salty\n",
      "token 1:\n",
      "\ttop_logprobs: s, probability: 99.94\n",
      "\ttop_logprobs: S, probability: 0.05\n",
      "\ttop_logprobs: sweet, probability: 0.0\n",
      "token 2:\n",
      "\ttop_logprobs: alty, probability: 100.0\n",
      "\ttop_logprobs: we, probability: 0.0\n",
      "\ttop_logprobs: our, probability: 0.0\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "Your task is to determine if that food is ONE of these classifications: sweet, salty, sour, bitter or umami.\n",
    "\n",
    "### Examples\n",
    "strawberry = sweet\n",
    "bacon = salty\n",
    "lemon = sour\n",
    "beer = bitter\n",
    "mushroom = umami\n",
    "\n",
    "### Expected Output\n",
    "One of sweet, salty, sour, bitter or umami. NOTHING ELSE.\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": \"baby back ribs = \"}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3\n",
    ")\n",
    "\n",
    "print(\"Prediction:\", response.choices[0].message.content)\n",
    "for i, content in enumerate(response.choices[0].logprobs.content):\n",
    "    print(f\"token {i + 1}:\")\n",
    "    for j, logprob in enumerate(content.top_logprobs):\n",
    "        probability = np.round(np.exp(logprob.logprob) * 100, 2)\n",
    "        print(f\"\\ttop_logprobs: {logprob.token}, probability: {probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5c672-0743-4103-a0ab-7dd2844c6f88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limiting Parameters\n",
    "\n",
    "* `max_tokens`: Max number of tokens to generate\n",
    "* `n`: Number of chat completion choices to generate\n",
    "* `stop`: Sequence where the API will stop generating further tokens \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b0250-231f-4526-93f6-6a981a8cfe63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Use Cases**\n",
    "* Fixed response length / cost management\n",
    "* Generating multiple options for gauging response cohesiveness\n",
    "* Strategic sequences for controlling response length\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b594a192-a002-4a17-8775-65f038df1277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c65b4e-9e40-43e2-94f5-318f7f96f256",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steaming bowl of pho\n",
      "Savoury broth and thin noodles\n",
      "Warm comfort in spoon\n",
      "\n",
      "Broth simmers gently\n",
      "Rice noodles and herbs enhance\n",
      "Pho warms the soul deep\n",
      "\n",
      "Savory broth and noodles\n",
      "Tender meats and fresh herbs float\n",
      "Warm comfort in a bowl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a haiku about the provided food\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pho\"}\n",
    "    ],\n",
    "    # max_tokens=100,\n",
    "    n=3\n",
    "    # stop=\"\\n\"\n",
    ")\n",
    "\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfff9dc-3f02-4fb0-a67a-99f71b5fa0d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Structured Output\n",
    "\n",
    "* JSON Output\n",
    "* Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3858aa-cecc-47b5-a2cf-3209dcfa9b42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### JSON Output\n",
    "\n",
    "* Model is constrained to only generate strings that parse into valid JSON object\n",
    "* Must instruct the model to produce JSON somewhere in the system message\n",
    "* Formatting/examples are important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8385ba2a-ea8f-4e53-a15c-cb2f31ebd595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Pancakes', 'style': 'American'}\n",
      "{'name': 'Avocado Toast', 'style': 'Modern'}\n",
      "{'name': 'Oatmeal with Berries', 'style': 'Healthy'}\n",
      "{'name': 'Scrambled Eggs with Bacon', 'style': 'Classic'}\n",
      "{'name': 'Breakfast Burrito', 'style': 'Tex-Mex'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "resp = ollama_client.chat.completions.create(\n",
    "    model=\"gemma2:9b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            # Task\n",
    "            You will be given a meal (breakfast/lunch/dinner). Generate a JSON list of 5 dishes for that meal.\n",
    "            \n",
    "            # Expected Format:\n",
    "            { \"dishes\": [ {\"name\": \"<dish>\", \"style\": \"<dish style>\"}, ... ] }\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"breakfast\",\n",
    "        }\n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" }\n",
    ")\n",
    "\n",
    "for dish in json.loads(resp.choices[0].message.content)[\"dishes\"]:\n",
    "    print(dish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12573ff9-6b6c-4503-b757-b7b17478fe22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6e5ae-139f-4d3b-968b-5094905dcf14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Types are important for bringing some semblance of order to an otherwise chaotic system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc6e37-86aa-47f2-89b8-f1f912a70d80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "[Pydantic](https://docs.pydantic.dev/latest/) is the defacto type validation library for Python powered by type annotations\n",
    "```python\n",
    "class DishList(BaseModel):\n",
    "    dishes: List[Dish] = Field(..., description=\"Contains a list of dish objects containing name and style\")\n",
    "\n",
    "class Dish(BaseModel):\n",
    "    name: str\n",
    "    style: str = Field(..., description=\"The dish type i.e. Mexican, Japanese etc.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e8883-ec7d-49d1-b8a8-ee186f36b501",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "[Instructor](https://python.useinstructor.com/why/) is a library that shims various LLM provider with the ability to validate and return Pydantic types\n",
    "```python\n",
    "client.chat.completions.create(\n",
    "    ...,\n",
    "    response_model=DishList\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c847ad2e-fd23-4c6b-aaa4-6961e28fc816",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dish: Pancakes with Maple Syrup, Style: American\n",
      "Dish: Breakfast Burrito, Style: Mexican\n",
      "Dish: Avocado Toast, Style: Modern/Healthy\n",
      "Dish: Scrambled Eggs with Bacon, Style: Classic American\n",
      "Dish: Yogurt Parfait, Style: Greek/Breakfast Bowls\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import instructor\n",
    "\n",
    "class Dish(BaseModel):\n",
    "    name: str\n",
    "    style: str = Field(..., description=\"The dish type i.e. Mexican, Japanese etc.\")\n",
    "\n",
    "class DishList(BaseModel):\n",
    "    dishes: List[Dish] = Field(..., description=\"Contains a list of dish objects containing name and style\")\n",
    "\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "instructor_client = instructor.from_openai(ollama_client, mode=instructor.Mode.JSON)\n",
    "\n",
    "response = instructor_client.chat.completions.create(\n",
    "    model=\"gemma2:9b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            # Task\n",
    "            You will be given a meal (breakfast/lunch/dinner). Generate a JSON list of 5 dishes for that meal.\n",
    "            \n",
    "            # Expected Format:\n",
    "            { \"dishes\": [ {\"name\": \"<dish>\", \"style\": \"<dish style>\"}, ... ] }\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"breakfast\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=DishList\n",
    ")\n",
    "\n",
    "for dish in response.dishes:\n",
    "    print(f\"Dish: {dish.name}, Style: {dish.style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569925e3-3e5b-45a4-a7b3-a3326ef96680",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Function Calling\n",
    "* Open AI Tools\n",
    "* Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dd985-74a1-462c-b160-b3a42bc6567f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Open AI Tools\n",
    "\n",
    "Model is constrained to predict which function(s) and argument(s) should be called to achieve a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f0d6b-17b8-416e-9daf-5fd6651af949",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Assuming we have functions like this in our codebase:\n",
    "```python\n",
    "def get_weather(location: str, unit: str):\n",
    "    return ...\n",
    "\n",
    "def google_search(query: str):\n",
    "    return ...\n",
    "```\n",
    "\n",
    "How can we get an LLM to intelligently choose which tools to call?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b97d1c-d7bc-4392-8036-04f731ff8a27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8744a4d1-cf54-4c1b-bc9d-3a43c726bf12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "google_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"Queries google for a search query\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search query\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4873250d-72ab-4c92-ab28-9988ebd1de69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"location\": \"Toronto, ON\", \"unit\": \"celsius\"}', name='get_weather')\n",
      "Function(arguments='{\"location\": \"Dallas, TX\", \"unit\": \"celsius\"}', name='get_weather')\n",
      "Function(arguments='{\"query\": \"super bowl winner\"}', name='google_search')\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "aoai_client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider, \n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\"\n",
    ")\n",
    "\n",
    "response = aoai_client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You must always use tools\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in toronto and dallas and who won the super bowl?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=[weather_tool, google_tool]\n",
    ")\n",
    "\n",
    "for tool in response.choices[0].message.tool_calls:\n",
    "    print(tool.function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fc029-e8f1-4c59-b617-73de5795e4f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Example with Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1251f68-17f0-4e70-a443-8e2ed3715664",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Weather'> location='Toronto' units='celsius'\n",
      "<class '__main__.Weather'> location='Dallas' units='celsius'\n",
      "<class '__main__.GoogleSearch'> query='Super Bowl winner'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Iterable, Literal\n",
    "import instructor\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    location: str = Field(..., description = \"The city and state, e.g. San Francisco, CA\")\n",
    "    units: Literal[\"celsius\", \"fahrenheit\"]\n",
    "\n",
    "class GoogleSearch(BaseModel):\n",
    "    query: str = Field(..., description = \"The search query\")\n",
    "\n",
    "instructor_client = instructor.from_openai(aoai_client, mode=instructor.Mode.PARALLEL_TOOLS)\n",
    "\n",
    "response = instructor_client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You must always use tools\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather in toronto and dallas and who won the super bowl?\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=Iterable[Weather | GoogleSearch]\n",
    ")\n",
    "\n",
    "for function in response:\n",
    "    print(type(function), function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0d34f-6e2b-44f9-aff6-2d5672674807",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Agents with Semantic Kernel\n",
    "\n",
    "Semantic Kernel is an [open-source library from MSFT](https://learn.microsoft.com/en-us/semantic-kernel/overview/) that lets you build AI agents and integrate the latest AI models with bindings in C#, Python, and Java."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf2beb-41d2-4d7e-b894-ebf33d364f99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "An \"agent\" in Semantic Kernel consists of:\n",
    "* `Persona`: Instruction / meta prompt setting the overall purpose of the agent\n",
    "* `Kernel`: Central DI container that orchestrates LLM logic\n",
    "  * `AI Service(s)`: LLMs the `Kernel` has access to\n",
    "  * `Plugin(s)`: Functions/tools the `Kernel` can use to complete tasks\n",
    "  * `Planner(s)`: Workflows the `Kernel` generates using a combination of `AI Service(s)` and `Plugin(s)` for task planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038b169-c565-43ae-9c86-f5e20f778ddf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Initializing a Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "299d4737-4f67-4940-9ad3-639dc7b95271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), scope)\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "        endpoint=\"https://oai-vena-copilot-npr-canadaeast-01.openai.azure.com\",\n",
    "        deployment_name=\"gpt-35-turbo\",\n",
    "        ad_token_provider=token_provider\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203da0b-f125-46b4-b426-f7388d54ed19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Initializing Native Plugins**\n",
    "\n",
    "Defines types and functions the LLM has access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e467f5-fe9b-4747-9d0b-7e981c6ca702",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, TypedDict, Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "import random\n",
    "\n",
    "class Weather(TypedDict):\n",
    "    location: str\n",
    "    unit: str\n",
    "    temperature: float\n",
    "\n",
    "class WeatherPlugin:\n",
    "   @kernel_function(\n",
    "      name=\"get_weather\",\n",
    "      description=\"Get the current weather in a given location\",\n",
    "   )\n",
    "   def get_weather(self, \n",
    "                   location: Annotated[str, \"Location to retrieve weather for\"], \n",
    "                   unit: Annotated[str, \"celsius or fahrenheit\"]) -> Annotated[Weather, \"The weather for a given location\"]:\n",
    "      return Weather(location=location, unit=unit, temperature=random.randint(10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38d9c3-9341-4e98-b78f-f3d023dd332a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Executing a Standalone Kernel**\n",
    "\n",
    "* SK bridges the gap by taking the functions the LLM predicted and calling them automatically in our code.\n",
    "* Under the hood, it uses parallel function calling as the default planner implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51bd1848-2f49-4f10-be87-e3ff76fcdcc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > The current weather in Toronto is 36°F and in San Antonio is 45°F.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"Weather\",)\n",
    "\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Enable auto-function calling\n",
    "execution_settings = AzureChatPromptExecutionSettings(tool_choice=\"auto\")\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_message({\"role\": \"user\", \"content\": \"What's the weather in Toronto and San Antonio in freedom units?\"})\n",
    "\n",
    "# Get the response from the AI\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "  chat_history=history,\n",
    "  settings=execution_settings,\n",
    "  kernel=kernel,\n",
    "  arguments=KernelArguments(),\n",
    "))[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Assistant > \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542871d-7616-4b80-bc66-5f0441868a1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75d336-0fe1-44ba-a176-763b632341c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcbccff-ad10-4c5e-889d-6996876a199c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac467b-aafb-4067-b4d9-2812c27707a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Visualizing Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6498093e-d3b7-47ec-af17-730809b31c42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b1c91-85ea-4a1d-86bf-e4fdefec46bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Hybrid Search and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd08a7c-abe9-4731-b4a7-b584d5165044",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e687cd3-f64a-401f-bbcf-e43b2afe8edb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Promptflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fbf17-e4c9-4dd4-80f0-1ce147839ac1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b085eca-15d7-4551-b0dc-e7de6ed07144",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Allows developers to create DAG based workflows with LLMs, prompts, and code\n",
    "* Baked in development tools for experimentation and observability\n",
    "* First class benchmarking/evaluation support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1792a-0c8c-40c4-83cd-43de6ce54f3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Anatomy of a flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d0849-da6e-42a6-8d38-56253dcb92cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Flows are essentially functions with expected inputs/outputs\n",
    "* Each `node` in a `flow` represents some intermediary step in a `flow` and can be run in parallel\n",
    "* An invocation of a `flow` is called a `run` and PF automatically captures metadata about aspects of that `run`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e3360-239a-47c8-8577-f4706ce76860",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![image](images/pf-dag-screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dca36b-7e19-4bf5-83a6-848252b09ca3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Example Flow Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447e5cd-fc26-4df8-b772-ce963ca47beb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Sample that performs RAG on Qdrant documentation and writes a tweet about a given topic.\n",
    "\n",
    "* Uses a dataset that is already chunked containing bits from Qdrant's documentation\n",
    "* Leverages prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af5aec-232d-4264-b466-0cf83d5ff896",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Experimentation + Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9fb93-66fa-4c97-b825-08a0263ca42b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Built in UIs greatly help with inspecting each phase of a test\n",
    "* Tracking token usage\n",
    "* Batch runs for testing a flow against a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348ee97-e7ef-4d2b-be8f-0d4287c32990",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Testing a flow with single input:\n",
    "```\n",
    "pf flow test --flow promptflow/qdrant_tweet_flow --inputs topic=Microsoft\n",
    "```\n",
    "\n",
    "Batch running flow against a dataset:\n",
    "```\n",
    "pf run create --flow promptflow/qdrant_tweet_flow --data promptflow/qdrant_tweet_flow/data.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c3644-21f5-4929-b4d3-4e0ae6d7fd8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Evaluations + Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9aa1a4-d5c7-4fe0-9ae1-ae778eb9c77d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* You can't improve what you don't measure\n",
    "* Evaluations are also flows and can run against output of previous runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79210b4-eb83-47a9-99ee-c01f21588d81",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Batch running evaluation flow against existing run:\n",
    "```\n",
    "pf run create --flow promptflow/evaluation_flow \\\n",
    "--data promptflow/evaluation_flow/data.jsonl \\\n",
    "--column-mapping sentiment='${data.sentiment}' tweet='${run.outputs.tweet}' \\\n",
    "--run <RUN_NAME>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08750187-323f-45b3-b24c-bccae79b9f7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Thank You!\n",
    "\n",
    "Code + Slides can be found here: https://github.com/khchan/building-blocks-ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
